Q: How we can deal with missing values?
A: 1. Check if value is not missed becaused we fail to aquire it
A: 2. Remove rows 
A: 3. Impute missing values (constant, mean, median, randomly selected from other values, estimated)
A: 4. Impute and marke missing value (assuming they missed for a reason)
A: 5. Use implementation of algorithm that accepts missing values (kNN may ignore, Naive Bayes - no problem)

Q: What kind of normalization do you know?
A: Z Normalization (standarization): mean at 0 std at 1
A: Min-Max Normalization rescales data range to [0-1]
A: Unit Vector Normalization - dividing every entry in a vector by its magnitude 
A: to create a vector of length 1 known as the unit vector
A: Magnitude of vector - we square each element of vector, sum them and take a root squre

Q: Why normalization is important in traditional ML and in NN?
A: Regression
A: - improves numerical stability of the model
A: - speeds up the training process
A: - gives ‘equal’ considerations for each feature
A: NN:
A: -  Large input values saturate activation functions such as sigmoid or ReLu(negative input). 
A: These types of activation functions feedback small or no gradient at all 
A: in the saturated region and therefore slows down training.

Q: What is a saturated neuron? 
A: A neuron that predominantly outputs values close to the asymptotic 
A: ends of the bounded activation function

Q: What is convergence? Like loss function convergence?
A: Convergence is a state during training in which loss settles 
A: to within an error range around the final value

Q: How to deal with small labeled dataset (Active Learning Strategy)?
A: - get 10% properly labeled data
A: - train a model
A: - use that to predict the rest (90%) of your data
A: - label 10% of the worst predictions***
A: - repeat
A: -------------------------------------------
A: ***Here are some existing methods that you can use:
A: - Least Confidence Uncertainty
A: - Smallest Margin Uncertainty
A: - Entropy Reduction

Q: How to normalize inputs in case of transfer learning?
A: They should be normalized by the same mean and standard deviation
A: that was used during the training of the pre-trained model

Q: Pytorch how to download pretrained models and how to normalize?
A: import torchvision.models as models
A: resnet18 = models.resnet18(pretrained=True)
A: alexnet = models.alexnet(pretrained=True)
A: vgg16 = models.vgg16(pretrained=True)
A: All pre-trained models expect input images normalized in the same way, i.e. mini-batches of 
A: 3-channel RGB images of shape (3 x H x W), where H and W are expected to be at least 224. 
A: The images have to be loaded in to a range of [0, 1] and then normalized using 
A: mean = [0.485, 0.456, 0.406] and std = [0.229, 0.224, 0.225]. 
A: You can use the following transform to normalize:
A: normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])
A: https://pytorch.org/vision/0.8/models.html

Q: How to freeze all the parameters in the model (for example to do a transfer learning)?
A: for param in model.parameters():
A:   param.requires_grad = False

Q: Pseudo-code to transfer learning with resnet18 and a binary classification
A: from torchvision import models
A: device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
A: model = models.resnet18(pretrained=False).to(device) 
A: for param in model.parameters():
A:   param.requires_grad = False
A: model.avgpool = nn.AdaptiveAvgPool2d(output_size=(1,1))
A: model.fc = nn.Sequential(nn.Flatten(), nn.Linear(512,128), nn.ReLU(),
A:            nn.Dropout(0.2), nn.Linear(128,1), nn.Sigmoid())
A: loss = nn.BCELoss()
A: optimizer = torch.optim.Adam(model.parameters(), lr=0.00005)

Q: Facicial key points detection - what is the key challenge on the data side?
A: To represent key points as a proportion of original image
A: as we are going to resize the original image. Thanks to this the location 
A: of key points do not change, regardless of the size of the source image

Q: What is the library with pre-trained models for 2D and 3D facial key point detection?
A: face-alignment 
A: https://github.com/1adrianb/face-alignment

Q: What are 2 forms of derrivatives of logistic function?
A: sig(x) = 1 / (1 + exp(-x))
A: sig'(x) = exp(-x) / (1 + exp(-x))^2
A: or
A: sig'(x) = sig(x) * (1 - sig(x))

Q: How to read a single row of index idx from a pandas.DataFrame
Q: for example to use it in __getitem__ method of Dataset class?
A: def __getitem__(self, idx):
A:   f = self.df.iloc[idx].squeeze()
A:   atr1 = f.atr1
A:   atr2 = f.atr2
A:   ...

Q: What mechanism to use if we want to do some transformations on a batch?
A: Use collate_fn parameter of a DataLoader constructor
A: def collate_fn(self, batch): # we assume it's a method of Dataset class
A:   do_some_stuff
A: train_loader = DataLoader(train_dataset, batch_size=32, drop_last=True, 
A:                collate_fn = train_dataset.collate_fn)

Q: Does Python supports multiple Inheritance?
A: Python does support multiple inheritance, unlike Java. 
A: Multiple inheritance means that a class can be derived 
A: from more than one parent classes.

Q: Define encapsulation in Python?
A: Encapsulation means binding the code and the data together. 
A: A Python class is an example of encapsulation.

Q: How do you do data abstraction in Python?
A: Data Abstraction is providing only the required details 
A: and hiding the implementation from the world. 
A: It can be achieved in Python by using interfaces and abstract classes.

Q: Which databases are supported by Python?
A: MySQL (Structured) and MongoDB (Unstructured) are the databases 
A: that are supported natively in Python. 

Q: Write a code to display the current time?
A: currenttime= time.localtime(time.time())
A: print (“Current time is”, currenttime)

Q: What is transfer learning?
A: A technique where we transfer model trained on a generic dataset
A: to the specific dataset of interest. Typically, the pre-trained models used to 
A: perform transfer learning are trainrd on millions of generic images.
A: Examples:
A: VGG16
A: ResNet 
A: EfficientNet

Q: Briefly explain VGG16
A: Created in Oxford in 2014
A: 16 stands for the # of layers in the model
A: GoogleNet was winning architecture but VGG is beatifully simple yet effective
A: abds with great track record

Q: Briefly explain ResNet architekcture
A: With too deep networks come 2 problems
A: 1. In forward propagation last layers have almost no information about original input
A: 2. In backpropagation layers near input receive hardly any gradient updates
A: Residual Networks solve those problems by introducing highway-like skip connections 
A: that transfer raw information to remote layers. The backward gradient will also 
A: flow freely to the initial layers.

Q: What are ReLU alternatives?
A: Leaky ReLU f(x) = max(0.01*x, x)
A: PReLU - Parametric Rectifier f(x) = max(alfa*x, x)
A: alfa can be backprop and learnt

Q: How to initialize with xavier?
A: For each layer (conv and fc) we put init command in the __init__() method
A: e.g.
A: self.conv3 = nn.Conv2d(16, 16, 5)
A: nn.init.xavier_uniform_(self.conv3.weight)
A: self.fc1 = nn.Linear(16*24*24, 1024)
A: nn.init.xavier_uniform_(self.fc1.weight)
A: nn.init.zeros_(self.fc1.bias)

Q: What kind of inputs and targets nn.CrossEntropyLoss expects?
A: For nn.CrossEntropyLoss the target has to be a single number 
A: from the interval [0, #classes] instead of a one-hot encoded target vector.
A: Replace your one-hot-encoded targets:
A: [1, 0] --> 0
A: [0, 1] --> 1
A: As for inputs it expects raw, unnormlized scores for each class
A: (Probably) Equivalent of nn.LogSoftmax and nn.NLLLoss.

Q: How to convers list of tensors (like list of accuracies or losses) from gpu to cpu?
A: new_tensor = torch.tensor(list_of_cuda_tensors, device = 'cpu')

Q: Famous CNN architectures
A: 1. LeNet-5   1998 LeCun (32x32x3)
A: 2. AlexNet   2012 Krizhevsky (227x227x3)
A: 3. VGGNet    2014 Simonyan & Ziesserman (224x224x3)
A: 4. GoogLeNet 2014 Szegedy (inception module + small # of params)
A: 5. ResNet    2015 He (152 layers, rapid reduction of spatial and skip connections)

Q: What is unsupervised learing?
A: The whole point in supervised learning is to learn function to
A: map input to output, having data with labels
A: With unsupervised learning we do not have labels and we learn 
A: some structure of data
A: examples: clustering, dimentionality reduction, feature learning
A: generative models 

Q: What is traditional Autoencoder?
A: We some data X and we pass it through some encoder network
A: to produce some latent features Z. It's a little bit like a learnable 
A: principal component analysis when we take our input data and then
A: convert it into some feature representation. Z ususally smaller than X (dim reduction) 
A: As we do not have labels we need to invent some surogate task that we can use 
A: and this task is ususally the idea of reconstruction through Decoder
A: ex: imgaes -> 4-layer conv (encoder) -> 4-layer upconv (Decoder) -> images 
A: Loss function: we compare input to output using e.g simple L2 Loss
A: L2 often gives poor result -> use Variational Autoencoder based on Bayesian statistics
A: After training we usually throw away Decoder and we may use traing encoder 
A: to initialize a supervised model. Like when we have small labeled train dataset
A: and a lot of unsupervised data. 
