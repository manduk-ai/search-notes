Q: PyTorch: how to calculate sum and dot product of 2 vectors
Q: [1,2,3] and [3,4,5]
A: t_one = torch.tensor([1, 2, 3])
A: t_two = torch.tensor([3, 4, 5])
A: Sum
A: t_one + t_two -> tensor([4, 6, 8])
A: dot product
A: torch.dot(t_one, t_two) -> 26

Q: How to create float tensor - 3 ways
A: float_tensor1 = torch.tensor([4.,5.,6.])
A: float_tensor2 = torch.tensor([4,5,6], dtype=torch.float)
A: float_tensor3 = torch.FloatTensor([4,5,6])
A: print(float_tensor1.dtype, float_tensor2.dtype, float_tensor3.dtype)
A: >>>torch.float32 torch.float32 torch.float32

Q: Pytorch: How to generate N equally spaced numbers from 0 to 10?
A: torch.linspace(0, 10, 3)
A: >>> tensor([ 0.,  5., 10.])

Q: How to create a tensor out of list
A: To prevent the original data type:
A: torch.tensor([1,2,3,4]) or
A: torch.as_tensor([1,2,3,4])
A: If you need specific type: torch.FloatTensor or IntTensor 

Q: How to convert a tensor into numpy array?
A: the simple case (no GPU involved): t.numpy()
A: but usually t.detach().cpu().numpy()
A: In in case the tensor is (or can be) on GPU, 
A: or in case it requires (or can require) grad.

Q: What would be the result: torch.arange(0, 25, 2)
A: tensor([ 0,  2,  4,  6,  8, 10, 12, 14, 16, 18, 20, 22, 24])

Q: How to create 2-d tensor using arrange and view
A: torch.arange(0, 8)
A: >>> tensor([0, 1, 2, 3, 4, 5, 6, 7])
A: one_d.view(4,-1)
A: >>> tensor([[0, 1],
A:             [2, 3],
A:             [4, 5],
A:             [6, 7]])

Q: What is regularization and what is L1 regularization?
A: Regularization is a technique to prevent overfitting. 
A: Overfitting may come from a model being overly complex and overly flexible.
A: Overly complex - to many features. Overly flexible - to sensitive to noise.
A: L1 is called Lasso and is used to reduce model complexity.
A: It introduces penalty term to a loss function: absolute values of the regression coefficients (∣β∣).
A: L1 minimizes the regression coefficients to regularize the model parameters. 
A: Sometimes, Lasso can reduce regression coefficients to zero, 
A: which is particularly important when it comes to feature selection.
A: Use Lasso when there is a small dataset with a large number of features.

Q: What is regularization and what is L2 regularization?
A: Regularization is a technique to prevent overfitting. 
A: Overfitting may come from a model being overly complex and overly flexible.
A: Overly complex - to many features. Overly flexible - to sensitive to noise.
A: L2 is called Ridge and is used to reduce model flexibility.
A: It introduces penalty term to a loss function: squared value of the regression coefficients
A: Higher values of the coefficients represent a model with greater flexibility. 
A: To minimize the function, these coefficients should be small. 
A: L2 regularization ensures the coefficients do not rise too high.

Q: What is a regression?
A: Regression is a statistical method that attempts to determine the strength and character 
A: of the relationship between one dependent variable (usually denoted by Y) 
A: and a series of other variables (known as independent variables).
A: Linear, Logistic, Lasso, Ridge - all are regression methods

Q: What is a condition for matrix multiplication?
A: A*B only when # columns A = # rows B
