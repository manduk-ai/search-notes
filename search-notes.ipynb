{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this notebook is to "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to set up a number of variables we going to use later in the notebook:\n",
    "- OPENAI_API_KEY: to access the OpenAI embeddings (secret)\n",
    "- AZURESEARCH_ADMIN_KEY: to access the Azure Search service (secret)\n",
    "- AZURESEARCH_ENDPOINT (theoretically it's not a secret, but it's better to keep it in .env file)\n",
    "- AZURESEARCH_INDEX_NAME (theoretically it's not a secret, but it's better to keep it in .env file)\n",
    "- if you create index in Azure Portal (not programatically), the default field names will be different than the ones assumed by the AzureSearch in langchain_community package. You can set the following variables to match the field names in your index:\n",
    "    - AZURESEARCH_FIELDS_CONTENT_VECTOR=text_vector (it's not a secret) \n",
    "    - AZURESEARCH_FIELDS_ID=chunk_id (it's not a secret)\n",
    "    - AZURESEARCH_FIELDS_CONTENT=chunk (it's not a secret)\n",
    "    \n",
    "All above will be read from .env file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = load_dotenv(find_dotenv(filename='.env'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we need is to build a retriever. \n",
    "\n",
    "\n",
    "We will use Microsoft AI Search with hybrid mode to retrieve the most relevant documents for a given query.\n",
    "\n",
    "Source code for langchain_community.vectorstores.azuresearch: \n",
    "https://api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/azuresearch.html#AzureSearch.similarity_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores.azuresearch import AzureSearch\n",
    "\n",
    "# OpenAI API data (for embeddings)\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai_api_version = \"2023-05-15\"\n",
    "model = \"text-embedding-ada-002\"\n",
    "\n",
    "# Azure AI Search data (for vector store)\n",
    "vector_store_address = os.getenv(\"AZURESEARCH_ENDPOINT\") \n",
    "vector_store_password = os.getenv(\"AZURESEARCH_ADMIN_KEY\")\n",
    "vector_store_index = os.getenv(\"AZURESEARCH_INDEX_NAME\")\n",
    "\n",
    "# Initialize the embeddings\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    openai_api_key=openai_api_key, \n",
    "    openai_api_version=openai_api_version, \n",
    "    model=model\n",
    ")\n",
    "\n",
    "# Alternatively, we may use AzureOpenAIEmbeddings\n",
    "# from langchain_openai import AzureOpenAIEmbeddings\n",
    "# embeddings = AzureOpenAIEmbeddings(\n",
    "#     model=\"<embeding-model>\",\n",
    "#     azure_endpoint=\"<Azure_openai_endpoint>\",\n",
    "#     azure_ad_token_provider=token_provider\n",
    "# )\n",
    "\n",
    "# Initialize the vector store\n",
    "vector_store = AzureSearch(\n",
    "    azure_search_endpoint=vector_store_address,\n",
    "    azure_search_key=vector_store_password,\n",
    "    index_name=vector_store_index,\n",
    "    embedding_function=embeddings.embed_query,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There multiple way of seting up the retriever, the issue here is to initialize it this way that is uses hybrid not only similarity search\n",
    "# I use this one: https://stackoverflow.com/questions/78576496/hybrid-search-using-azure-ai-search-and-lang-chain-as-a-retriever\n",
    "retriever = vector_store.as_retriever(k=5, search_type=\"hybrid\")\n",
    "\n",
    "# There is also Azure AI Search retriever https://python.langchain.com/v0.2/docs/integrations/retrievers/azure_ai_search/\n",
    "# Here is the doc: https://python.langchain.com/v0.2/docs/integrations/retrievers/azure_ai_search/\n",
    "\n",
    "# Another way discussed here: https://github.com/langchain-ai/langchain/discussions/18752"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some example queries\n",
    "# query = \"What are the fully local agents?\"\n",
    "# query = \"What is Nvidia NIM API?\"\n",
    "query = \"What is a generator function?\"\n",
    "docs = retriever.invoke(query)\n",
    "for doc in docs:\n",
    "    print(doc.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports required for chains\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser, JsonOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define two versions of the chain - one with Ollama (llama3.1) and one with OpenAI (gpt-4o-mini)\n",
    "# PROVIDER = \"ollama\"\n",
    "PROVIDER = \"openai\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The main chain - it will use retrieved documents to generate an answer to the user question\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"You are an assistant for question-answering tasks. \n",
    "    \n",
    "    Analyze carefully and use the following documents to answer the user question. \n",
    "    \n",
    "    If you don't know the answer, just say that you don't know. Do not make up an answer. \n",
    "    \n",
    "    Keep your answer short and to the point.\n",
    "    \n",
    "    Question: {question} \n",
    "    Documents: {documents} \n",
    "    Answer: \n",
    "    \"\"\",\n",
    "    input_variables=[\"question\", \"documents\"],\n",
    ")\n",
    "\n",
    "if PROVIDER == \"openai\":\n",
    "    llm = ChatOpenAI(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        temperature=0,\n",
    "    )\n",
    "else:\n",
    "    llm = ChatOllama(\n",
    "        model=\"llama3.1\",\n",
    "        temperature=0,\n",
    "    )\n",
    "\n",
    "main_chain = prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the main chain\n",
    "main_chain.invoke({\"question\": \"What's my city?\", \"documents\": \"I'm based in Kuala Lumpur\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define a evaluator chain - it will evaluate if information retrieved by RAG retriver \n",
    "# is sufficient to answer the question. It returns yes or no in a JSON format.\n",
    "eval_prompt = PromptTemplate(\n",
    "    template=\"\"\"Your task is to carefully evaluate if information in Documents provided below is sufficient for answering User Question.  \n",
    "    User Question: {question} \n",
    "    Documents: {documents} \n",
    "\n",
    "    Return your Evaluation in JSON format with a single key 'Evaluation' and binary score 'yes' or 'no'. No other keys, values or preambles are allowed.\n",
    "    \n",
    "    If you don't know the answer pick 'no'.\n",
    "    \n",
    "    Evaluation: \n",
    "    \"\"\",\n",
    "    input_variables=[\"question\", \"documents\"],\n",
    ")\n",
    "\n",
    "if PROVIDER == \"openai\":\n",
    "    eval_llm = ChatOpenAI(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        temperature=0,\n",
    "        model_kwargs={ \"response_format\": { \"type\": \"json_object\" } },\n",
    "    )\n",
    "else:\n",
    "    eval_llm = ChatOllama(\n",
    "        model=\"llama3.1\",\n",
    "        temperature=0,\n",
    "        format=\"json\",\n",
    "    )\n",
    "\n",
    "eval_chain = eval_prompt | eval_llm | JsonOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the evaluator chain - positive case\n",
    "eval_chain.invoke({\"question\": \"What's my city?\", \"documents\": \"I'm based in Kuala Lumpur\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the evaluator chain - negative case\n",
    "eval_chain.invoke({\"question\": \"What's my city?\", \"documents\": \"US presidential elections are in November\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define websearch tool - we use Tavilyn for this\n",
    "from langchain.schema import Document\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "web_search_tool = TavilySearchResults()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use LangGraph, we need to define GraphState class. This class persists the state of the graph or in other words, it stores a session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict, List\n",
    "from langgraph.graph import START, END, StateGraph\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of the graph.\n",
    "\n",
    "    Attributes:\n",
    "        question: question\n",
    "        documents: list of retrieved documents\n",
    "        answer: LLM generated answer\n",
    "        search_required: whether to search web\n",
    "        search_results: results of web search\n",
    "        steps: steps of the graph execution\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    question: str\n",
    "    documents: List[str]\n",
    "    answer: str\n",
    "    search_required: bool\n",
    "    search_results: List[str]\n",
    "    steps: List[str]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the sections below we will create a series of functions that will serve as nodes in the graph: retrieve, evaluate, generate and search-web."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieves documents using previously defined retriever.\n",
    "# consumes a state with a question\n",
    "# returns a new state with documents added and appended step\n",
    "def retrieve(state):\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    documents = retriever.invoke(question)\n",
    "    \n",
    "    steps = state[\"steps\"]\n",
    "    steps.append(\"retrieve_documents\")\n",
    "    \n",
    "    return {\n",
    "        \"documents\": documents, \n",
    "        \"question\": question, \n",
    "        \"steps\": steps\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generates an answer using previously defined main_chain\n",
    "# consumes a state with a question and documents\n",
    "# returns a new state with answer added and appended step\n",
    "def generate(state):\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    search_required = state[\"search_required\"]\n",
    "    search_results = state[\"search_results\"]\n",
    "    \n",
    "    # if search was required and results are available, we use them instead of retrieved documents\n",
    "    if search_required and search_results:\n",
    "        documents = search_results\n",
    "\n",
    "    answer = main_chain.invoke({\"documents\": documents, \"question\": question})\n",
    "\n",
    "    steps = state[\"steps\"]\n",
    "    steps.append(\"generate_answer\")\n",
    "    \n",
    "    return {\n",
    "        \"documents\": documents,\n",
    "        \"question\": question,\n",
    "        \"answer\": answer,\n",
    "        \"search_required\": search_required,\n",
    "        \"search_results\": search_results,\n",
    "        \"steps\": steps,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluates if the documents are relevant to the question\n",
    "# consumes a state with a question and documents\n",
    "# returns a new state with search_required added and appended step\n",
    "def evaluate(state):\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    steps = state[\"steps\"]\n",
    "    steps.append(\"evaluate_retrieval\")\n",
    "\n",
    "    # Evaluate if the documents are relevant to the question\n",
    "    evaluation = eval_chain.invoke({\"documents\": documents, \"question\": question})\n",
    "\n",
    "    # if the evaluation is negative we set search_required to True\n",
    "    search_required = False\n",
    "    search_required = evaluation[\"Evaluation\"] == \"no\"\n",
    "\n",
    "    return {\n",
    "        \"documents\": documents,\n",
    "        \"question\": question,\n",
    "        \"search_required\": search_required,\n",
    "        \"steps\": steps,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# searches the web for documents that may help to answer the question\n",
    "# consumes the question \n",
    "# produces the search results\n",
    "def web_search(state):\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    search_required = state[\"search_required\"]\n",
    "    steps = state[\"steps\"]\n",
    "    steps.append(\"web_search\")\n",
    "    \n",
    "    results = web_search_tool.invoke({\"query\": question})\n",
    "\n",
    "    search_results = [\n",
    "        Document(page_content=doc[\"content\"], metadata={\"url\": doc[\"url\"]})\n",
    "        for doc in results\n",
    "    ]\n",
    "\n",
    "    return {\n",
    "        \"documents\": documents, \n",
    "        \"question\": question,\n",
    "        \"search_required\": search_required,\n",
    "        \"search_results\": search_results,\n",
    "        \"steps\": steps\n",
    "    }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "searchnotes_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
