{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this notebook is to "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to set up a number of variables we going to use later in the notebook:\n",
    "- OPENAI_API_KEY: to access the OpenAI embeddings (secret)\n",
    "- AZURESEARCH_ADMIN_KEY: to access the Azure Search service (secret)\n",
    "- AZURESEARCH_ENDPOINT (theoretically it's not a secret, but it's better to keep it in .env file)\n",
    "- AZURESEARCH_INDEX_NAME (theoretically it's not a secret, but it's better to keep it in .env file)\n",
    "- if you create index in Azure Portal (not programatically), the default field names will be different than the ones assumed by the AzureSearch in langchain_community package. You can set the following variables to match the field names in your index:\n",
    "    - AZURESEARCH_FIELDS_CONTENT_VECTOR=text_vector (it's not a secret) \n",
    "    - AZURESEARCH_FIELDS_ID=chunk_id (it's not a secret)\n",
    "    - AZURESEARCH_FIELDS_CONTENT=chunk (it's not a secret)\n",
    "    \n",
    "All above will be read from .env file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we need is to build a retriever. \n",
    "\n",
    "\n",
    "We will use Microsoft AI Search with hybrid mode to retrieve the most relevant documents for a given query.\n",
    "\n",
    "Source code for langchain_community.vectorstores.azuresearch: \n",
    "https://api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/azuresearch.html#AzureSearch.similarity_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores.azuresearch import AzureSearch\n",
    "\n",
    "# OpenAI API data (for embeddings)\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai_api_version = \"2023-05-15\"\n",
    "model = \"text-embedding-ada-002\"\n",
    "\n",
    "# Azure AI Search data (for vector store)\n",
    "vector_store_address = os.getenv(\"AZURESEARCH_ENDPOINT\") \n",
    "vector_store_password = os.getenv(\"AZURESEARCH_ADMIN_KEY\")\n",
    "vector_store_index = os.getenv(\"AZURESEARCH_INDEX_NAME\")\n",
    "\n",
    "# Initialize the embeddings\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    openai_api_key=openai_api_key, \n",
    "    openai_api_version=openai_api_version, \n",
    "    model=model\n",
    ")\n",
    "\n",
    "# Alternatively, we may use AzureOpenAIEmbeddings\n",
    "# from langchain_openai import AzureOpenAIEmbeddings\n",
    "# embeddings = AzureOpenAIEmbeddings(\n",
    "#     model=\"<embeding-model>\",\n",
    "#     azure_endpoint=\"<Azure_openai_endpoint>\",\n",
    "#     azure_ad_token_provider=token_provider\n",
    "# )\n",
    "\n",
    "# Initialize the vector store\n",
    "vector_store = AzureSearch(\n",
    "    azure_search_endpoint=vector_store_address,\n",
    "    azure_search_key=vector_store_password,\n",
    "    index_name=vector_store_index,\n",
    "    embedding_function=embeddings.embed_query,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There multiple way of seting up the retriever, the issue here is to initialize it this way that is uses hybrid not only similarity search\n",
    "# I use this one: https://stackoverflow.com/questions/78576496/hybrid-search-using-azure-ai-search-and-lang-chain-as-a-retriever\n",
    "retriever = vector_store.as_retriever(k=2, search_type=\"hybrid\")\n",
    "\n",
    "# There is also Azure AI Search retriever https://python.langchain.com/v0.2/docs/integrations/retrievers/azure_ai_search/\n",
    "# Here is the doc: https://python.langchain.com/v0.2/docs/integrations/retrievers/azure_ai_search/\n",
    "\n",
    "# Another way discussed here: https://github.com/langchain-ai/langchain/discussions/18752"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some example queries\n",
    "# query = \"What are the fully local agents?\"\n",
    "# query = \"What is Nvidia NIM API?\"\n",
    "query = \"What is a generator function?\"\n",
    "docs = retriever.invoke(query)\n",
    "for doc in docs:\n",
    "    print(doc.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #from https://github.com/langchain-ai/langchain/discussions/18752\n",
    "\n",
    "# prompt = \"Why is the sky blue?\"\n",
    "\n",
    "# # Use a \"regular\" similarity search, but with the hybrid option\n",
    "# docs = vector_store.similarity_search(\n",
    "#     query=prompt,\n",
    "#     k=10,\n",
    "#     search_type=\"hybrid\",\n",
    "#     filters=f\"source eq 'A'\" #If you want to use filters\n",
    "# )\n",
    "\n",
    "# # Create the RAG chain\n",
    "# rag_chain_from_docs = (\n",
    "#     RunnablePassthrough.assign(context=(lambda x: format_docs(x[\"context\"])))\n",
    "#     | prompt_template\n",
    "#     | llm\n",
    "#     | StrOutputParser()\n",
    "# )\n",
    "\n",
    "# # Prepare the input for the RAG chain\n",
    "# rag_input = {\"query\": prompt, \"context\": docs}\n",
    "\n",
    "# # Generate the answer using the RAG chain\n",
    "# rag_output = rag_chain_from_docs.invoke(rag_input)\n",
    "\n",
    "# # Create the final output dictionary manually\n",
    "# answer = {\n",
    "#     \"context\": docs,\n",
    "#     \"question\": prompt,\n",
    "#     \"answer\": rag_output\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "searchnotes_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
